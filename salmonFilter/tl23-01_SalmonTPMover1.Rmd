---
title: "tl22-01_VvxTPMover1"
output: 
  html_document:
    theme: cosmo
    code_download: true
    toc: true
    number_sections: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

# Intro

This script filters the de novo transcripts from P. vivax for those that match pirs, and are expressed.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      results = TRUE, 
                      message = FALSE, 
                      warning = FALSE)
options(scipen = 999) 
# Means that numbers are displayed normally not as 1e6 (1000000)
```

```{r loading_packages, include = FALSE, message = FALSE}
# Load the required packages
library('readr')
library('dplyr')
library('stringr')
library('purrr')
library('kableExtra')
# library('plotly')
library('rmarkdown')
library('seqinr')

safe_colorblind_palette <- c("#88CCEE", "#CC6677", "#DDCC77", "#117733", "#332288", "#AA4499", 
                             "#44AA99", "#999933", "#882255", "#661100", "#6699CC", "#888888")
global_save_var <- FALSE
```

```{r function_ordering}
ordering <- function(to_order, order_vector, fromLast = TRUE){
  order = unlist(sapply(order_vector, 
                        function(x){unique(str_subset(to_order, 
                                                      pattern = paste(x)))}))
  order_missing = unique(to_order[!to_order %in% order])
  unique(c(order, order_missing), fromLast = fromLast)
}
```

```{r function_uniquify}
#Make unique identifiers from a vector of names by appending '_X' where X is the number of the 'replicate'.
uniquify <- function(vector_names, first_one = TRUE){
  new_vector <- c()
  df_num <- data.frame(names = unique(vector_names), rep = 1)
  if(first_one){
    duplicated_names <- unique(vector_names[duplicated(vector_names)])
  }else{
    duplicated_names <- c()
  }
  for(i in 1:length(vector_names)){
    if(vector_names[i] %in% duplicated_names|!first_one){
      name <- paste(vector_names[i],
                    df_num$rep[match(vector_names[i], df_num$names)],
                    sep = '_')
      #Increase rep counter
      df_num$rep[match(vector_names[i], df_num$names)] <- df_num$rep[match(vector_names[i], df_num$names)] + 1
      new_vector[i] <- name
    }else{
      new_vector[i] <- vector_names[i]
    }
  }
  new_vector
}
```

```{r function_read_HMMertxtgz}
read_HMMertxtgz <- function(hmmer_gz.path) {
  hmmer_gz_all.df <- readLines(hmmer_gz.path)
  header.index <- first(which(grepl(hmmer_gz_all.df, 
                                    pattern = 'E-value')))
  end.index <- first(which(grepl(hmmer_gz_all.df, 
                                 pattern = 'inclusion threshold|Domain annotation for each sequence')))
  if(any(grepl(hmmer_gz_all.df, pattern = 'Domain annotation for each sequence'))) end.index <- end.index - 2
  hmmer_gz.df <- hmmer_gz_all.df[c(header.index,
                                   (header.index+2):(end.index - 1))]
  hmmer_gz.df <- sapply(hmmer_gz.df, function(line){
    #Split by whitespace and remove the first element of each line (which is blank)
    str_split(line, pattern = "\\s+")[[1]][-1]
  })
  #Get the number of columns as this informs where the sequence information column is 
  # (this column can contain blank space and be difficult to parse otherwise)
  num_cols <- length(hmmer_gz.df[[1]])
  #Save column names for later
  col_nam <- hmmer_gz.df[[1]]
  #Edit column names to remove duplicates and clarify what they mean.
  col_nam <- c(paste0(col_nam[1:3], "_fullseq"), paste0(col_nam[4:6], "_bestdom"), paste0(col_nam[7:8], "_numdom"), col_nam[9:10])
  hmmer_gz.df <- lapply(hmmer_gz.df[-1], 
                        function(line){
                          data.frame(t(unlist(c(line[1:num_cols - 1], 
                                                paste(line[num_cols:length(line)], 
                                                      collapse = "")))))
                        }) %>% bind_rows
  colnames(hmmer_gz.df) <- col_nam
  hmmer_gz.df <-  mutate(hmmer_gz.df, Sequence = as.character(Sequence))
  
  #I can't get this working in 'mutate' for whatever reason, so have to do it manually and then add it in.
  hmm_cvrg.vec <- unlist(lapply(hmmer_gz.df$Sequence, function(Sequence) {
    as.numeric(strsplit(hmmer_gz_all.df[which(str_detect(hmmer_gz_all.df, 
                                                         pattern = Sequence))[2]+3],
                        split = '\\s+')[[1]][9]) - as.numeric(strsplit(hmmer_gz_all.df[which(str_detect(hmmer_gz_all.df, 
                                                                                                        pattern = Sequence))[2]+3],
                                                                       split = '\\s+')[[1]][8])
  }))
  
  hmmer_gz.df$hmm_cvrg <- hmm_cvrg.vec
  
  return(hmmer_gz.df)
}
```


```{r load_salmon}
# experiment.vec <- c('Bourgard21')
experiment.vec <- c('Bourgard21', 'Imp22', 'K19', 'Meul22',
                    'R20', 'S20-Z16', 'B20-C19-G19-G18-M19-K17')

quant.files <- c(
  system("ls ../../nextflow/vvx_*/salmon/*/quant.sf", 
       intern = TRUE),
  system("ls ../../salmon_manual/quant/*/quant.sf", 
       intern = TRUE)
)

assemblies.list <- str_extract(quant.files, pattern = '(?<=_vvx_T[[:digit:]]{1,2}_).+(?=/quant.sf)') %>% unique

# Load in the quant.sf data by lapply-ing across the experiment/Nextflow analysis names above.
# quant.df <- lapply(assemblies.list,
#                    function(assembly.nam){
#                      print(paste0("Doing ", assembly.nam))
#                      
#                      # Mistake: Some results files from earlier pipeline outputs helpfully don't follow the same nomenclature:
#                      # e.g. Kim17_SRX5158495_SRR8347532_vvx.txt.gz (old) Kim17_SRX5158495-SRR8347532_vvx.txt.gz (new) - note the '_' and '-'.
#                      # pattern = '(SRX|ERX).+_(SRR|ERR).+(?=_vvx)'
#                      
#                      # Which folder are the non-Salmon results in?
#                      
#                      # tryCatch(system2(paste0("ls ../../nextflow/vvx_*/hmmer/", assembly.nam, ".txt.gz")), 
#                      #          error = function(err) {
#                      #            system(paste0("ls ../../nextflow/*/vvx_*/hmmer/", assembly.nam, ".txt.gz"),
#                      #                   intern = TRUE)
#                      #          })
#                      
#                      #Fasta file
#                      
#                      fasta.path <- system(paste0("ls ../../nextflow/vvx_*/evigene/okayset/", assembly.nam, ".okay.aa"), 
#                             intern = TRUE)
#                      
#                      stopifnot(length(fasta.path) == 1)
#                      
#                      #HMMer results - requires a decent amount of processing - put into a function.
#                      hmmer_gz.path <- system(paste0("ls ../../nextflow/vvx_*/hmmer/", assembly.nam, ".txt.gz"), 
#                             intern = TRUE)
#                      
#                      stopifnot(length(hmmer_gz.path) == 1)
#                      
#                      if(!any(grepl(readLines(hmmer_gz.path),
#                                    pattern = 'No targets detected that satisfy reporting thresholds'))){
#                        hmmer_gz.df <- read_HMMertxtgz(hmmer_gz.path) %>%
#                          mutate(Name = Sequence)
#                      } else {
#                        #Create an empty data.frame when there are no HMMer matches
#                        hmmer_gz.df <- setNames(data.frame(matrix(ncol = 11, nrow = 1)),
#                                                c("E-value_fullseq", "score_fullseq", "bias_fullseq", "E-value_bestdom",
#                                                  "score_bestdom", "bias_bestdom", "exp_numdom", "N_numdom", "Sequence",
#                                                  "Description", "Name"))
#                      }
#                      
#                      
#                      # Get the quant files for this assembly
#                      assembly_quant.files <- str_subset(quant.files,
#                                                         pattern = assembly.nam)
#                      
#                      # For each quant file do:
#                      
#                      lapply(assembly_quant.files, function(qnt){
#                        
#                        # Get the samples mapped in these quant files
#                        
#                        sample.nam <- str_extract(qnt,
#                                                  pattern = '(?<=(salmon|quant)/).+_vvx_T[[:digit:]]{1,2}(?=_.+/quant.sf)')
#                        
#                        #Read in the qnt file and add information, including whether the transcripts is a hmmer match.
#                        read.delim(qnt) %>%
#                          mutate(source = str_extract(qnt, '(?<=/(salmon|quant)/).+(?=/quant.sf)'),
#                                 sample =  sample.nam,
#                                 assembly = assembly.nam,
#                                 file_source = qnt,
#                                 # results_path = results.path,
#                                 hmmer_path = hmmer_gz.path,
#                                 fasta_path = fasta.path)
#                      }) %>%
#                        bind_rows %>%
#                        # Combine with the HMMer
#                        left_join(hmmer_gz.df, by = 'Name')
#                      }) %>% bind_rows
# 
# quant.df <- mutate(quant.df, hmm_cvrg_perc = (hmm_cvrg/380)*100)

# write_csv(quant.df, path = 'salmonQuant_all.csv')

#read_csv is faster but may populate an entire column with NA. ?readr::cols
quant.df <- read.csv(file = 'salmonQuant_all.csv')

#QC: Which sample names are NA:
# filter(quant.df, is.na(sample)) %>% .$source %>% unique

# Test the numbers of assemblies and sample files.
# str_extract(quant.files, pattern = '(?<=_vvx_T[[:digit:]]{1,2}_).+(?=/quant.sf)') %>% unique %>% str_subset('Imp') %>% length
# quant.files %>% str_subset('Rangel') %>% length

```

```{r quant_filtered}
# Grouping by each assembly and transcript, which transcripts have TPM and NumReads < 1 TPM in every sample.
#. i.e. Filter out every transcript with at least one sample with >= 1 TPM/NumReads.
# quant_filtered.df <- group_by(quant.df, 
#                               assembly,
#                               fasta_path,
#                               Name) %>% 
#   filter(any(TPM >= 1 & NumReads >= 1)) %>% 
#   filter(!is.na(hmm_cvrg) & hmm_cvrg_perc >= 75)
# write_csv(quant_filtered.df, path = 'salmonQuant_filtered.csv')
quant_filtered.df <- read.csv('salmonQuant_filtered.csv')

hist(na.omit(quant.df$hmm_cvrg_perc), breaks = 1000)
hist(quant_filtered.df$hmm_cvrg_perc, breaks = 100)

# quant_filtered.df %>% filter(TPM < 1)

# How many genes/pir genes are kept for each assembly
( quant_stats.df <- group_by(quant.df, assembly) %>% 
    summarise(prop_all = 100*n_distinct(Name[TPM >= 1 & NumReads >= 1])/n_distinct(Name),
              num_pir = n_distinct(Name[!is.na(Sequence)]),
              prop_pir_tpm = 100*n_distinct(Name[TPM >= 1 & NumReads >= 1 & !is.na(Sequence)])/n_distinct(Name[!is.na(Sequence)]),
              prop_pir_hmm = 100*n_distinct(Name[hmm_cvrg_perc >= 75 & !is.na(Sequence)])/n_distinct(Name[!is.na(Sequence)]),
              prop_pir_filt = 100*n_distinct(Name[TPM >= 1 & NumReads >= 1 & !is.na(Sequence) & hmm_cvrg_perc >= 75])/n_distinct(Name[!is.na(Sequence)]),
              num_pir_filt = n_distinct(Name[TPM >= 1 & NumReads >= 1 & !is.na(Sequence) & hmm_cvrg_perc >= 75])) %>% 
    arrange(prop_pir_filt) )
arrange(quant_stats.df, assembly)
mutate(quant_stats.df,expt = str_extract(assembly, pattern = '^[[:alpha:]]+[[:digit:]]{2}(?=_)')) %>% 
  group_by(expt) %>% summarise(num_pir_filt = sum(num_pir_filt)) %>% arrange(num_pir_filt) 
# %>% .$num_pir_filt %>% sum()
sum(quant_stats.df$num_pir_filt)
```

Extract the fasta files of pirs expressed above threshold. 

```{r fasta}
#Note that this function appends to an existing file so be sure to remove it if it already exists.
#Save date for file name.
# date.str <- format(Sys.time(), "%d%b")
# lapply(unique(quant_filtered.df$fasta_path),
#        function(fasta.path){
#          pir_names <- unique(filter(quant_filtered.df, 
#                                     fasta_path == fasta.path)$Name)
#          assembly_nam <- unique(filter(quant_filtered.df, 
#                                        fasta_path == fasta.path)$assembly)
#          fasta.fa <- read.fasta(fasta.path)
#          fasta_pir.fa <- fasta.fa[getName(fasta.fa) %in% pir_names]
#          write.fasta(fasta_pir.fa, names = paste0(getName(fasta_pir.fa), '_', assembly_nam),
#                      file.out = paste0('../../deNovoPirs/deNovoPirs_',date.str,'.fasta'), open = 'a')
#        }) 
```

Make the node.df file for graph design. Using the concatenated fasta file of the above filtered de novo pirs and reference gene pirs.

```{r subfam}
lopez13_sal1Subfam <- read.table('../../../tl22-02_VirSubfamNetwork/pir_info/lopez13_vir_subfam.txt', 
                                 col.names = c('name','subfam'),
                                 stringsAsFactors = FALSE)
deNovo_Ref_pirs.list <- getName(read.fasta(file = '../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho.fasta'))
subfam.df <- data.frame(Name = deNovo_Ref_pirs.list,
                        subfam = case_when(grepl(deNovo_Ref_pirs.list, pattern = 'Nonam') ~ "de_novo",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PVX') ~ "vvxSal1",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'P01') ~ "vvxP01",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PVW1') ~ "vvxW1",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PCYB') ~ "cynoB",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PcyM') ~ "cynoM",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'Poc') ~ "ovale",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PKA1') ~ "knowlA",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PKNOH') ~ "knowlH",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PKNH') ~ "knowlM",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PmUG01') ~ "malar",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PVL') ~ "vvxlike",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PCOAH') ~ "coat",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'MKS88') ~ "brasl"),
                        stringsAsFactors = FALSE) %>%
  mutate(species = ifelse(subfam == 'de_novo',
                          'vvx',
                          str_extract(subfam, pattern = '^[[:lower:]]+'))
  )

subfam.df$subfam[grepl(subfam.df$Name, pattern = 'PVX')] <- sapply(str_subset(subfam.df$Name, pattern = 'PVX'), 
                                                                    function(sal1_id) {
                                                                      if(sal1_id %in% lopez13_sal1Subfam$name) {
                                                                        lopez13_sal1Subfam$subfam[which(lopez13_sal1Subfam$name %in% sal1_id)]
                                                                      } else {
                                                                        'vvxSal1'
                                                                      }
                                                                    })

# Test subfam assignment
# left_join(lopez13_sal1Subfam, mutate(subfam.df, name = Name), by = 'name')

write_csv(subfam.df,
          path = '../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_Sal1subfam.csv')
```

Preparing the data for Gephi input requires some special treatment, including making a number for each node.

```{r gephi}
# Get the median TPM and NumReads for each assembly de novo pir
quant_filtered_sequence.df <-  mutate(quant_filtered.df, 
                                      Name_assembly = paste0(Name, '_', assembly)) %>% 
  # Grouping over all variables except those that are sample specific (as opposed to assembly specific)
  group_by(pick(!matches(c('source|sample|file_source|TPM|NumReads|EffectiveLength')))) %>% 
  summarise(TPM_med = median(TPM),
            TPM_max = max(TPM),
            TPM_min = min(TPM),
            NumReads_med = median(NumReads),
            NumReads_max = max(NumReads),
            NumReads_min = min(NumReads))

gephi.df <- mutate(subfam.df, 
                   Id = seq_along(Name),
                   label = Name,
                   subfam = subfam,
                   Name_assembly = Name) %>% 
  select(-Name) %>% 
  left_join(quant_filtered_sequence.df, by = c('Name_assembly')) %>% 
  relocate(Id, label)

```

```{r mcl}
mcl.files <- list.files(path = '../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_mcl',
           pattern = 'deNovoPirs-23Apr_pirsVvxVvxOrtho_all2all.mci.I.+list',
           full.names = TRUE)
#Read in the mcl files and combine them by the name using Reduce to apply full_join across the list.
mcl.df <- lapply(mcl.files, function(mcl_file){
  mcl_infl <- str_extract(mcl_file, pattern = '(?<=\\.)I.+(?=\\.list$)')
  read.table(mcl_file, col.names = c('label', mcl_infl))
}) %>% Reduce(function(x,y) full_join(x,y, by = c('label')), .)

gephi_mcl.df <- full_join(gephi.df, mcl.df, by = 'label')

write_csv(gephi_mcl.df,
          path = '../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_info.csv')
```

```{r node}

blast.df <- read.table('../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_all2all.blast',
                      col.names = unlist(strsplit(c('qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovs qcovhsp slen nident'), split = ' ')))

# Duplicate removal removes many more than expected due to multiple different alignments from the same sequences.
#   TODO: How should I deal with these? Would be ideal to combine but this would take a while. May take lazy way out and just take the best match.

# Could make this faster by arranging by assembly and then saving the qseqid instances and removing the sseqid instances of each assembly going down the data frame.

#Remove self-matches.
blast_filt.df <- blast.df[apply(blast.df[,1:2], 1, function(x) if(x[1] == x[2]) FALSE else TRUE),]

#Arrange by e-value so the best matches come to the top.
blast_filt.df <- arrange(blast_filt.df, evalue)

blast_filt_dup <- apply(blast_filt.df[,1:2],1,sort) %>% t %>% duplicated
sum(blast_filt_dup)

blast_filt_dedup.df <- blast_filt.df[!blast_filt_dup,]

#Test that best match is returned.
pattern_filter <- 'NonamEVm000789t1_Cheng19_ERX2560129-ERR2541711_vvx|PVP01_0600400'
pattern_filter <- 'PcyM_1354500|PocGH01_00134500'
pattern_filter <- 'PVP01_0003840|PVW1_140089200'

filter(blast_filt_dedup.df, 
       grepl(qseqid, 
             pattern = pattern_filter), 
       grepl(sseqid, 
             pattern = pattern_filter))

filter(blast.df, 
       grepl(qseqid, 
                       pattern = pattern_filter), 
       grepl(sseqid, 
             pattern = pattern_filter))

edges.df <- mutate(blast_filt_dedup.df, 
       Source = gephi.df$Id[match(qseqid, gephi.df$label)],
       Target = gephi.df$Id[match(sseqid, gephi.df$label)],
       Type = 'undirected') %>% 
  select(Source, Target, Type)

write_csv(edges.df, 
          '../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_edges.csv')

```

```{r assembly_info}

assembly_info.df <- read.delim('/camp/lab/langhornej/working/HPC/littlet/tl22-01_vivaxDeNovo/tl22-01_assembly_info.txt') %>% 
  filter(!grepl(assembly, pattern = '0\\.9c|0\\.99'),
         !grepl(assembly, pattern = 'SRX5158513_SRR8347514|SRX5158512_SRR8347515'))  
#Filter out any none-0.95 assembly made. And potential Kim19_A duplicate?

#Order experiments by years
expt_num.vec <-ordering(unique(assembly_info.df$experiment), 
                                   order_vector = c(16:22))
#Get experiment numbers and add '0' to single digit numbers.
names(expt_num.vec) <-  paste0('E', 
                              sapply(seq_along(expt_num.vec), function(x){
                                ifelse(nchar(x)==1, 
                                       paste0('0', x),
                                       x)
                              }))

#Manually add Gunalan19 and _Boonkaew20 (in addition to Guna19 and Boonkaew20)
expt_num.vec <- c(expt_num.vec, E07 = 'Gunalan19', E08 = '_Boonkaew20')

#Get the relevant info from samplesheet otherwise loads of rows will be duplicated when joining.
samplesheet_small.df <- mutate(samplesheet, assembly_file = assembly) %>% 
  select(assembly_file, Cat.Sample.stage.s.) %>% unique

assembly_info_samplesheet.df <- left_join(assembly_info.df, samplesheet_small.df, by = 'assembly_file')

assembly_info_samplesheet.df <- mutate(assembly_info_samplesheet.df,
                                        experiment_num = names(expt_num.vec)[match(experiment,
                                                                                  expt_num.vec)])

#Get consistent shapes and colours for the graphs

shapes_val <- 1:length(unique(assembly_info_samplesheet.df$Cat.Sample.stage.s.))
names(shapes_val) <- unique(assembly_info_samplesheet.df$Cat.Sample.stage.s.)

colours_val <- safe_colorblind_palette[1:length(unique(names(expt_num.vec)))]
names(colours_val) <- unique(names(expt_num.vec))

expt_num.df <- data.frame(expt = expt_num.vec, 
                          expt_code = names(expt_num.vec), 
                          col = c(colours_val,colours_val['E07'],colours_val['E08']))

#Get the stages of the life cycle used for the assembly (altering the Gunalan sample name in over1.df since they do not correspond).
over1.df$stage <- assembly_info_samplesheet.df$Cat.Sample.stage.s.[
  match(str_replace(over1.df$assembly, pattern = 'Gunalan19', replacement = 'Guna19'), 
        str_extract(assembly_info_samplesheet.df$assembly, 
                    pattern = '.+(?=_scspades_0.95cdhitest)'))
]

#Get the experiment numbers (altering the Gunalan sample name in over1.df since they do not correspond).
over1.df$experiment_num <- assembly_info_samplesheet.df$experiment_num[
  match(str_replace(over1.df$assembly, pattern = 'Gunalan19', replacement = 'Guna19'), 
        str_extract(assembly_info_samplesheet.df$assembly, 
                    pattern = '.+(?=_scspades_0.95cdhitest)'))
]

#Save the colour scheme
assembly_info_samplesheet.df$expt_colour <- colours_val[match(assembly_info_samplesheet.df$experiment_num,
                                                  names(colours_val))]

#Save number of pir transcripts over 1 TPM (altering the Gunalan sample name in over1.df since they do not correspond).
pir_over1.df <- filter(over1.df, pir)  

assembly_info_samplesheet.df$num_mRNA_pir_over200aa_over1TPM <- pir_over1.df$over1_num[
  match(str_extract(assembly_info_samplesheet.df$assembly, 
                    pattern = '.+(?=_scspades_0.95cdhitest)'),
        str_replace(pir_over1.df$assembly, pattern = 'Gunalan19', replacement = 'Guna19'))
]

# Make NAs zero
assembly_info_samplesheet.df$num_mRNA_pir_over200aa_over1TPM <- ifelse(
  is.na(assembly_info_samplesheet.df$num_mRNA_pir_over200aa_over1TPM),
  0,
  assembly_info_samplesheet.df$num_mRNA_pir_over200aa_over1TPM 
)

write.table(assembly_info_samplesheet.df,
            '/camp/lab/langhornej/working/HPC/littlet/tl22-01_vivaxDeNovo/tl22-01_assembly_info_extra.txt')

```

```{r over1_plots}

(plot <- ggplot(data = filter(over1.df, !pir),
                aes(x = total, 
                    y = over1_perc,
                    col = experiment_num,
                    shape = stage)) +
    geom_point(size = 1, stroke = 2, alpha = .75) +
  scale_shape_manual(values=shapes_val,
                     name = 'Life cycle stage',
                     guide = guide_legend(ncol = 2)) +
  scale_color_manual(values = colours_val[!names(colours_val) %in% 'E10'],
                     name = 'Experiment',
                     guide = guide_legend(ncol = 2)) +
    xlab('Number of assembled transcripts') +
    ylab('Percentage of transcripts transcribed over 1 TPM') +
    theme_classic())

if(global_save_var){
  ggsave(plot = plot,
         '/camp/lab/langhornej/working/HPC/littlet/tl22-01_vivaxDeNovo/plots/assemblies_numTranscriptsOver1tpm_totalTranscripts.pdf',
         device = 'pdf',
         width = 7,
         height = 5,
         units = "in")
}

(plot <- ggplot(data = filter(over1.df, pir),
       aes(x = total, 
           y = over1_perc_pirs,
           col = experiment_num,
           shape = stage)) +
    geom_point(size = 1, stroke = 2, alpha = .75) +
    #Subset the shapes/colours_val since not all the experiments/stages have any predicted pirs and are hence not included.
    scale_shape_manual(values=shapes_val[
      names(shapes_val) %in% unique(filter(over1.df, 
                                           pir)$stage)
    ],
    name = 'Life cycle stage',
    guide = guide_legend(ncol = 2)) +
    scale_color_manual(values = colours_val[
      names(colours_val) %in% unique(filter(over1.df, 
                                            pir)$experiment_num)
    ],
    name = 'Experiment',
    guide = guide_legend(ncol = 2)) +
   xlab(expression(paste('Number of assembled ',italic(pir),' transcripts'))) +
   ylab(expression(paste('Percentage of ',italic(pir),'s transcribed over 1 TPM'))) +
   theme_classic())

if(global_save_var){
  ggsave(plot = plot,
         '/camp/lab/langhornej/working/HPC/littlet/tl22-01_vivaxDeNovo/plots/assemblies_numPirOver1tpm_totalTranscripts.pdf',
         device = 'pdf',
         width = 7,
         height = 5,
         units = "in")
}

```

