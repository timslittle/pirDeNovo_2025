---
title: "tl22-01_VvxTPMover1"
output: 
  html_document:
    theme: cosmo
    code_download: true
    toc: true
    number_sections: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

# Intro

This script filters the de novo transcripts from P. vivax for those that match pirs, and are expressed.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      results = TRUE, 
                      message = FALSE, 
                      warning = FALSE)
options(scipen = 999) 
# Means that numbers are displayed normally not as 1e6 (1000000)
```

```{r loading_packages, include = FALSE, message = FALSE}
# Load the required packages
library('readr')
library('dplyr')
library('stringr')
library('purrr')
library('kableExtra')
# library('plotly')
library('rmarkdown')
library('seqinr')
library('ggplot2')

safe_colorblind_palette <- c("#88CCEE", "#CC6677", "#DDCC77", "#117733", "#332288", "#AA4499", 
                             "#44AA99", "#999933", "#882255", "#661100", "#6699CC", "#888888")
global_save_var <- FALSE
```

```{r function_ordering}
ordering <- function(to_order, order_vector, fromLast = TRUE){
  order = unlist(sapply(order_vector, 
                        function(x){unique(str_subset(to_order, 
                                                      pattern = paste(x)))}))
  order_missing = unique(to_order[!to_order %in% order])
  unique(c(order, order_missing), fromLast = fromLast)
}
```

```{r function_uniquify}
#Make unique identifiers from a vector of names by appending '_X' where X is the number of the 'replicate'.
uniquify <- function(vector_names, first_one = TRUE){
  new_vector <- c()
  df_num <- data.frame(names = unique(vector_names), rep = 1)
  if(first_one){
    duplicated_names <- unique(vector_names[duplicated(vector_names)])
  }else{
    duplicated_names <- c()
  }
  for(i in 1:length(vector_names)){
    if(vector_names[i] %in% duplicated_names|!first_one){
      name <- paste(vector_names[i],
                    df_num$rep[match(vector_names[i], df_num$names)],
                    sep = '_')
      #Increase rep counter
      df_num$rep[match(vector_names[i], df_num$names)] <- df_num$rep[match(vector_names[i], df_num$names)] + 1
      new_vector[i] <- name
    }else{
      new_vector[i] <- vector_names[i]
    }
  }
  new_vector
}
```

```{r function_read_HMMertxtgz}
read_HMMertxtgz <- function(hmmer_gz.path) {
  hmmer_gz_all.df <- readLines(hmmer_gz.path)
  header.index <- first(which(grepl(hmmer_gz_all.df, 
                                    pattern = 'E-value')))
  end.index <- first(which(grepl(hmmer_gz_all.df, 
                                 pattern = 'inclusion threshold|Domain annotation for each sequence')))
  if(any(grepl(hmmer_gz_all.df, pattern = 'Domain annotation for each sequence'))) end.index <- end.index - 2
  hmmer_gz.df <- hmmer_gz_all.df[c(header.index,
                                   (header.index+2):(end.index - 1))]
  hmmer_gz.df <- sapply(hmmer_gz.df, function(line){
    #Split by whitespace and remove the first element of each line (which is blank)
    str_split(line, pattern = "\\s+")[[1]][-1]
  })
  #Get the number of columns as this informs where the sequence information column is 
  # (this column can contain blank space and be difficult to parse otherwise)
  num_cols <- length(hmmer_gz.df[[1]])
  #Save column names for later
  col_nam <- hmmer_gz.df[[1]]
  #Edit column names to remove duplicates and clarify what they mean.
  col_nam <- c(paste0(col_nam[1:3], "_fullseq"), paste0(col_nam[4:6], "_bestdom"), paste0(col_nam[7:8], "_numdom"), col_nam[9:10])
  hmmer_gz.df <- lapply(hmmer_gz.df[-1], 
                        function(line){
                          data.frame(t(unlist(c(line[1:num_cols - 1], 
                                                paste(line[num_cols:length(line)], 
                                                      collapse = "")))))
                        }) %>% bind_rows
  colnames(hmmer_gz.df) <- col_nam
  hmmer_gz.df <-  mutate(hmmer_gz.df, Sequence = as.character(Sequence))
  
  #I can't get this working in 'mutate' for whatever reason, so have to do it manually and then add it in.
  hmm_cvrg.vec <- unlist(lapply(hmmer_gz.df$Sequence, function(Sequence) {
    as.numeric(strsplit(hmmer_gz_all.df[which(str_detect(hmmer_gz_all.df, 
                                                         pattern = Sequence))[2]+3],
                        split = '\\s+')[[1]][9]) - as.numeric(strsplit(hmmer_gz_all.df[which(str_detect(hmmer_gz_all.df, 
                                                                                                        pattern = Sequence))[2]+3],
                                                                       split = '\\s+')[[1]][8])
  }))
  
  hmmer_gz.df$hmm_cvrg <- hmm_cvrg.vec
  
  return(hmmer_gz.df)
}
```


```{r load_salmon}
# experiment.vec <- c('Bourgard21')
experiment.vec <- c('Bourgard21', 'Imp22', 'K19', 'Meul22',
                    'R20', 'S20-Z16', 'B20-C19-G19-G18-M19-K17')

quant.files <- c(
  system("ls ../../nextflow/vvx_*/salmon/*/quant.sf", 
       intern = TRUE),
  system("ls ../../salmon_manual/quant/*/quant.sf", 
       intern = TRUE)
)

assemblies.list <- str_extract(quant.files, pattern = '(?<=_vvx_T[[:digit:]]{1,2}_).+(?=/quant.sf)') %>% unique

# Load in the quant.sf data by lapply-ing across the experiment/Nextflow analysis names above.
# quant.df <- lapply(assemblies.list,
#                    function(assembly.nam){
#                      print(paste0("Doing ", assembly.nam))
#                      
#                      # Mistake: Some results files from earlier pipeline outputs helpfully don't follow the same nomenclature:
#                      # e.g. Kim17_SRX5158495_SRR8347532_vvx.txt.gz (old) Kim17_SRX5158495-SRR8347532_vvx.txt.gz (new) - note the '_' and '-'.
#                      # pattern = '(SRX|ERX).+_(SRR|ERR).+(?=_vvx)'
#                      
#                      # Which folder are the non-Salmon results in?
#                      
#                      # tryCatch(system2(paste0("ls ../../nextflow/vvx_*/hmmer/", assembly.nam, ".txt.gz")), 
#                      #          error = function(err) {
#                      #            system(paste0("ls ../../nextflow/*/vvx_*/hmmer/", assembly.nam, ".txt.gz"),
#                      #                   intern = TRUE)
#                      #          })
#                      
#                      #Fasta file
#                      
#                      fasta.path <- system(paste0("ls ../../nextflow/vvx_*/evigene/okayset/", assembly.nam, ".okay.aa"), 
#                             intern = TRUE)
#                      
#                      stopifnot(length(fasta.path) == 1)
#                      
#                      #HMMer results - requires a decent amount of processing - put into a function.
#                      hmmer_gz.path <- system(paste0("ls ../../nextflow/vvx_*/hmmer/", assembly.nam, ".txt.gz"), 
#                             intern = TRUE)
#                      
#                      stopifnot(length(hmmer_gz.path) == 1)
#                      
#                      if(!any(grepl(readLines(hmmer_gz.path),
#                                    pattern = 'No targets detected that satisfy reporting thresholds'))){
#                        hmmer_gz.df <- read_HMMertxtgz(hmmer_gz.path) %>%
#                          mutate(Name = Sequence)
#                      } else {
#                        #Create an empty data.frame when there are no HMMer matches
#                        hmmer_gz.df <- setNames(data.frame(matrix(ncol = 11, nrow = 1)),
#                                                c("E-value_fullseq", "score_fullseq", "bias_fullseq", "E-value_bestdom",
#                                                  "score_bestdom", "bias_bestdom", "exp_numdom", "N_numdom", "Sequence",
#                                                  "Description", "Name"))
#                      }
#                      
#                      
#                      # Get the quant files for this assembly
#                      assembly_quant.files <- str_subset(quant.files,
#                                                         pattern = assembly.nam)
#                      
#                      # For each quant file do:
#                      
#                      lapply(assembly_quant.files, function(qnt){
#                        
#                        # Get the samples mapped in these quant files
#                        
#                        sample.nam <- str_extract(qnt,
#                                                  pattern = '(?<=(salmon|quant)/).+_vvx_T[[:digit:]]{1,2}(?=_.+/quant.sf)')
#                        
#                        #Read in the qnt file and add information, including whether the transcripts is a hmmer match.
#                        read.delim(qnt) %>%
#                          mutate(source = str_extract(qnt, '(?<=/(salmon|quant)/).+(?=/quant.sf)'),
#                                 sample =  sample.nam,
#                                 assembly = assembly.nam,
#                                 file_source = qnt,
#                                 # results_path = results.path,
#                                 hmmer_path = hmmer_gz.path,
#                                 fasta_path = fasta.path)
#                      }) %>%
#                        bind_rows %>%
#                        # Combine with the HMMer
#                        left_join(hmmer_gz.df, by = 'Name')
#                      }) %>% bind_rows
# 
# quant.df <- mutate(quant.df, hmm_cvrg_perc = (hmm_cvrg/380)*100)

# write_csv(quant.df, path = 'salmonQuant_all.csv')

#read_csv is faster but may populate an entire column with NA. ?readr::cols
quant.df <- read.csv(file = 'salmonQuant_all.csv')

#QC: Which sample names are NA:
# filter(quant.df, is.na(sample)) %>% .$source %>% unique

# Test the numbers of assemblies and sample files.
# str_extract(quant.files, pattern = '(?<=_vvx_T[[:digit:]]{1,2}_).+(?=/quant.sf)') %>% unique %>% str_subset('Imp') %>% length
# quant.files %>% str_subset('Rangel') %>% length

```

```{r quant_filtered}
# Grouping by each assembly and transcript, which transcripts have TPM and NumReads < 1 TPM in every sample.
#. i.e. Filter out every transcript with at least one sample with >= 1 TPM/NumReads.
# quant_filtered.df <- group_by(quant.df,
#                               assembly,
#                               fasta_path,
#                               Name) %>%
#   filter(any(TPM >= 1 & NumReads >= 1)) %>%
#   filter(!is.na(hmm_cvrg) & hmm_cvrg_perc >= 75)
# write_csv(quant_filtered.df, path = 'salmonQuant_filtered.csv')
quant_filtered.df <- read.csv('salmonQuant_filtered.csv')

hist(na.omit(quant.df$hmm_cvrg_perc), breaks = 1000)
hist(quant_filtered.df$hmm_cvrg_perc, breaks = 100)

# quant_filtered.df %>% filter(TPM < 1)

# How many genes/pir genes are kept for each assembly
( quant_stats.df <- group_by(quant.df, assembly) %>% 
    summarise(prop_all = 100*n_distinct(Name[TPM >= 1 & NumReads >= 1])/n_distinct(Name),
              num_pir = n_distinct(Name[!is.na(Sequence)]),
              prop_pir_tpm = 100*n_distinct(Name[TPM >= 1 & NumReads >= 1 & !is.na(Sequence)])/n_distinct(Name[!is.na(Sequence)]),
              prop_pir_hmm = 100*n_distinct(Name[hmm_cvrg_perc >= 75 & !is.na(Sequence)])/n_distinct(Name[!is.na(Sequence)]),
              prop_pir_filt = 100*n_distinct(Name[TPM >= 1 & NumReads >= 1 & !is.na(Sequence) & hmm_cvrg_perc >= 75])/n_distinct(Name[!is.na(Sequence)]),
              num_pir_filt = n_distinct(Name[TPM >= 1 & NumReads >= 1 & !is.na(Sequence) & hmm_cvrg_perc >= 75])) %>% 
    arrange(prop_pir_filt) )
arrange(quant_stats.df, assembly)
mutate(quant_stats.df,expt = str_extract(assembly, pattern = '^[[:alpha:]]+[[:digit:]]{2}(?=_)')) %>% 
  group_by(expt) %>% summarise(num_pir_filt = sum(num_pir_filt)) %>% arrange(num_pir_filt) 
# %>% .$num_pir_filt %>% sum()
sum(quant_stats.df$num_pir_filt)
```

Extract the fasta files of pirs expressed above threshold. 

```{r fasta}
#Note that this function appends to an existing file so be sure to remove it if it already exists.
#Save date for file name.
# date.str <- format(Sys.time(), "%d%b")
# lapply(unique(quant_filtered.df$fasta_path),
#        function(fasta.path){
#          pir_names <- unique(filter(quant_filtered.df, 
#                                     fasta_path == fasta.path)$Name)
#          assembly_nam <- unique(filter(quant_filtered.df, 
#                                        fasta_path == fasta.path)$assembly)
#          fasta.fa <- read.fasta(fasta.path)
#          fasta_pir.fa <- fasta.fa[getName(fasta.fa) %in% pir_names]
#          write.fasta(fasta_pir.fa, names = paste0(getName(fasta_pir.fa), '_', assembly_nam),
#                      file.out = paste0('../../deNovoPirs/deNovoPirs_',date.str,'.fasta'), open = 'a')
#        }) 
```

Make the node.df file for graph design. Using the concatenated fasta file of the above filtered de novo pirs and reference gene pirs.

```{r subfam}
lopez13_sal1Subfam <- read.table('../../../tl22-02_VirSubfamNetwork/pir_info/lopez13_vir_subfam.txt', 
                                 col.names = c('name','subfam'),
                                 stringsAsFactors = FALSE)
deNovo_Ref_pirs.list <- getName(read.fasta(file = '../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_wLopez13.fasta'))
subfam.df <- data.frame(Name = deNovo_Ref_pirs.list,
                        subfam = case_when(grepl(deNovo_Ref_pirs.list, pattern = 'Nonam') ~ "de_novo",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PVX') ~ "vvxSal1",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'P01') ~ "vvxP01",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PVW1') ~ "vvxW1",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PCYB') ~ "cynoB",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PcyM') ~ "cynoM",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'Poc') ~ "ovale",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PKA1') ~ "knowlA",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PKNOH') ~ "knowlH",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PKNH') ~ "knowlM",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PmUG01') ~ "malar",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PVL') ~ "vvxlike",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'PCOAH') ~ "coat",
                                           grepl(deNovo_Ref_pirs.list, pattern = 'MKS88') ~ "brasl"),
                        stringsAsFactors = FALSE) %>%
  mutate(species = ifelse(subfam == 'de_novo',
                          'vvx',
                          str_extract(subfam, pattern = '^[[:lower:]]+'))
  )

subfam.df$subfam[grepl(subfam.df$Name, pattern = 'PVX')] <- sapply(
  str_subset(subfam.df$Name, pattern = 'PVX'), 
  function(sal1_id) {
    if(sal1_id %in% lopez13_sal1Subfam$name) {
      lopez13_sal1Subfam$subfam[which(lopez13_sal1Subfam$name %in% sal1_id)]
    } else {
      'vvxSal1'
    }
  })

#Which Lopez sequences are missing from the PlasmoDB search?

# write.table(lopez13_sal1Subfam[!lopez13_sal1Subfam$name %in% subfam.df$Name,]$name,
#             file = '../../network/lopez13_sal1Subfam_missingPirs.txt',
#             row.names = FALSE,
#             col.name = FALSE,
#             quote = FALSE)

# Test subfam assignment
# left_join(lopez13_sal1Subfam, mutate(subfam.df, name = Name), by = 'name')

write_csv(subfam.df,
          path = '../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_wLopez13_Sal1subfam.csv')
```

Preparing the data for Gephi input requires some special treatment, including making a number for each node.

```{r gephi}
# Get the info for all the sequences for later.
quant_sequence.df <- mutate(quant.df, 
                                      Name_assembly = paste0(Name, '_', assembly)) %>% 
  # Grouping over all variables except those that are sample specific (as opposed to assembly specific)
  group_by(pick(!matches(c('source|sample|file_source|TPM|NumReads|EffectiveLength')))) %>% 
  summarise(TPM_med = median(TPM),
            TPM_max = max(TPM),
            TPM_min = min(TPM),
            NumReads_med = median(NumReads),
            NumReads_max = max(NumReads),
            NumReads_min = min(NumReads))

# Get the median TPM and NumReads for each assembly de novo pir
quant_filtered_sequence.df <-  mutate(quant_filtered.df, 
                                      Name_assembly = paste0(Name, '_', assembly)) %>% 
  # Grouping over all variables except those that are sample specific (as opposed to assembly specific)
  group_by(pick(!matches(c('source|sample|file_source|TPM|NumReads|EffectiveLength')))) %>% 
  summarise(TPM_med = median(TPM),
            TPM_max = max(TPM),
            TPM_min = min(TPM),
            NumReads_med = median(NumReads),
            NumReads_max = max(NumReads),
            NumReads_min = min(NumReads))

gephi.df <- mutate(subfam.df, 
                   Id = seq_along(Name),
                   label = Name,
                   subfam = subfam,
                   Name_assembly = Name) %>% 
  select(-Name) %>% 
  left_join(quant_filtered_sequence.df, by = c('Name_assembly')) %>% 
  relocate(Id, label)

#Prev issue: Why are a load of Meul22_Pv032 pirs in subfam.df but not quant_filtered_sequence.df.
## quant_filtered.df was out-of-date, may have not saved a previous iteration?

```

```{r mcl}
mcl.files <- list.files(path = '../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_wLopez13_mcl',
           pattern = 'deNovoPirs-23Apr_pirsVvxVvxOrtho_wLopez13_all2all.mci.I.+list',
           full.names = TRUE)
#Read in the mcl files and combine them by the name using Reduce to apply full_join across the list.
mcl.df <- lapply(mcl.files, function(mcl_file){
  mcl_infl <- str_extract(mcl_file, pattern = '(?<=\\.)I.+(?=\\.list$)')
  read.table(mcl_file, col.names = c('label', mcl_infl))
}) %>% Reduce(function(x,y) full_join(x,y, by = c('label')), .)

gephi_mcl.df <- full_join(gephi.df, mcl.df, by = 'label')

# any(is.na(gephi_mcl.df$Name_assembly))

write_csv(gephi_mcl.df,
          path = '../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_wLopez13_info.csv')
```

```{r best_network}
filter(gephi_mcl.df, 
       str_detect(subfam, pattern = '^(B|C|D|E|F|G|H|I|J|K)$')) %>%
  select(Id, label, subfam, starts_with('I')) %>% 
  data.table::melt(measure.vars = str_subset(colnames(gephi_mcl.df), 
                                             pattern = '^I[[:digit:]]'),
                   variable.name = 'inflation',
                   value.name = 'cluster_num') %>% 
  group_by(inflation, cluster_num, subfam) %>% 
  summarise(num_members = n_distinct(label)) %>% 
  summarise(num_members_clust = paste(subfam, paste0(' ', num_members), collapse = ', ')) %>% 
  summarise(cluster_member_summary = paste(paste0(cluster_num, ': ', num_members_clust), collapse = ' )( ')) %>% 
  arrange(inflation)

gephi_mcl.df %>% 
  select(-c(starts_with('I')), I1.4) %>% 
  group_by(subfam, species, I1.4) %>% 
  dplyr::summarise(number = n_distinct(label)) %>% 
  group_by(I1.4) %>% 
  mutate(perc_I = round(100*number/sum(number), digits = 2)) %>% 
  group_by(subfam,species) %>% 
  mutate(perc_spec = round(100*number/sum(number), digits = 2)) %>% 
  arrange(I1.4, desc(perc_I))
```

```{r subfam_graph}
subfam_col <- safe_colorblind_palette
names(subfam_col) <- c('E','G','K','J','I','B','C')

lapply( str_subset(colnames(gephi_mcl.df), pattern = '^I[[:digit:]]'),
        function(infl){
          subfam_graph.df <- gephi_mcl.df %>% 
            select(-c(starts_with('I')), infl) %>% 
            arrange(across(infl)) %>% 
            group_by(across(infl)) %>% 
            mutate(infl_net = factor(
                # do.call(
                paste0(get(infl), ' (n = ', n_distinct(label), ')')
                # , list(infl = infl, label = label)
              # )
            )) %>% 
          filter(str_detect(subfam, pattern = '^(B|C|D|E|F|G|H|I|J|K)$')) %>%
            # mutate(subfam = ifelse(str_detect(subfam, pattern = '^(B|C|D|E|F|G|H|I|J|K)$'),
            #                      subfam, 
            #                      'none')) %>% 
            group_by(subfam, species, infl_net) %>% 
            dplyr::summarise(number = n_distinct(label))
          
          max_y <- max(summarise(group_by(subfam_graph.df, infl_net), sum_num = sum(number))$sum_num)
          breaks_y <- seq(0, plyr::round_any(max_y, 5, ceiling), 5)
          
          (subfam_graph.plot <- ggplot(subfam_graph.df, aes(x = infl_net, y = number, fill = subfam)) +
              geom_col(postion = 'stack') +
              xlab('Cluster ID (total number of pirs in cluster)') +
              ylab('Number of Sal1 pirs') +
              scale_fill_manual(values = subfam_col, 
                                name = 'Sal1 sub-family') +
              scale_y_continuous(breaks = breaks_y, 
                                 # limits = c(0, max(breaks_y))
              ) +
              theme_classic()+
              theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) )
        })
```

```{r save_I14}
infl <- 'I1.4'

subfam_graph.df <- gephi_mcl.df %>% 
  select(-c(starts_with('I')), infl) %>% 
  arrange(across(infl)) %>% 
  group_by(across(infl)) %>% 
  mutate(infl_net = factor(
    # do.call(
    paste0(get(infl), ' (n = ', n_distinct(label), ')')
    # , list(infl = infl, label = label)
    # )
  )) %>% 
  filter(str_detect(subfam, pattern = '^(B|C|D|E|F|G|H|I|J|K)$')) %>%
  # mutate(subfam = ifelse(str_detect(subfam, pattern = '^(B|C|D|E|F|G|H|I|J|K)$'),
  #                      subfam, 
  #                      'none')) %>% 
  group_by(subfam, species, infl_net) %>% 
  dplyr::summarise(number = n_distinct(label))

max_y <- max(summarise(group_by(subfam_graph.df, infl_net), sum_num = sum(number))$sum_num)
breaks_y <- seq(0, plyr::round_any(max_y, 5, ceiling), 5)

(subfam_graph.plot <- ggplot(subfam_graph.df, aes(x = infl_net, y = number, fill = subfam)) +
    geom_col(postion = 'stack') +
    xlab('Cluster ID (total number of pirs in cluster)') +
    ylab('Number of Sal1 pirs') +
    scale_fill_manual(values = subfam_col, 
                      name = 'Sal1 sub-family') +
    scale_y_continuous(breaks = breaks_y, 
                       # limits = c(0, max(breaks_y))
    ) +
    theme_classic()+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) )

ggsave('../../plots/vivax_subfamDisI14Network.pdf', 
       subfam_graph.plot)

```


```{r node}
# Comment out when not needed as this takes a long time.

# blast.df <- read.table('../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_wLopez13_all2all.blast',
#                       col.names = unlist(strsplit(c('qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovs qcovhsp slen nident'), split = ' ')))
# 
# # Duplicate removal removes many more than expected due to multiple different alignments from the same sequences.
# #   TODO: How should I deal with these? Would be ideal to combine but this would take a while. May take lazy way out and just take the best match.
# 
# # Could make this faster by arranging by assembly and then saving the qseqid instances and removing the sseqid instances of each assembly going down the data frame.
# 
# #Remove self-matches.
# blast_filt.df <- blast.df[apply(blast.df[,1:2], 1, function(x) if(x[1] == x[2]) FALSE else TRUE),]
# # could just do function(x) x[1] != x[2] ?
# 
# #Arrange by e-value so the best matches come to the top.
# blast_filt.df <- arrange(blast_filt.df, evalue)
# 
# blast_filt_dup <- apply(blast_filt.df[,1:2],1,sort) %>% t %>% duplicated
# sum(blast_filt_dup)
# 
# blast_filt_dedup.df <- blast_filt.df[!blast_filt_dup,]
# 
# #Test that best match is returned.
# pattern_filter <- 'NonamEVm000789t1_Cheng19_ERX2560129-ERR2541711_vvx|PVP01_0600400'
# pattern_filter <- 'PcyM_1354500|PocGH01_00134500'
# pattern_filter <- 'PVP01_0003840|PVW1_140089200'
# 
# filter(blast_filt_dedup.df, 
#        grepl(qseqid, 
#              pattern = pattern_filter), 
#        grepl(sseqid, 
#              pattern = pattern_filter))
# 
# filter(blast.df, 
#        grepl(qseqid, 
#                        pattern = pattern_filter), 
#        grepl(sseqid, 
#              pattern = pattern_filter))
# 
# edges.df <- mutate(blast_filt_dedup.df, 
#        Source = gephi.df$Id[match(qseqid, gephi.df$label)],
#        Target = gephi.df$Id[match(sseqid, gephi.df$label)],
#        Type = 'undirected') %>% 
#   select(Source, Target, Type)
# 
# write_csv(edges.df, 
#           '../../network/deNovoPirs-23Apr_pirsVvxVvxOrtho_wLopez13_edges.csv')

```

```{r assembly_stats}
# assembly_numTranscript <- quant_sequence.df %>% 
#   group_by(assembly,fasta_path) %>% 
#   # Use the same metrics as before to count the number of pirs, using *_max now.
#   summarise(num_pir = n_distinct(Name[TPM_max >= 1 & NumReads_max >= 1 & !is.na(hmm_cvrg) & hmm_cvrg_perc >= 75])) %>% 
#   arrange(desc(num_pir), assembly) %>% 
#   mutate(num_transcripts = system(paste0('grep ">" ',fasta_path,'| wc -l'), intern = TRUE),
#          expt = str_extract(assembly, pattern = '^.+(?=_.+_vvx)'))
# 
# assembly_busco <- lapply(unique(quant_sequence.df$hmmer_path), 
#        function(hmmer.path){
#          res.path = str_extract(hmmer.path, pattern = '.+vvx_.+(?=/hmmer)')
#          assembly.nam = unique(quant_sequence.df$assembly[quant_sequence.df$hmmer_path == hmmer.path])
#          busco.df = read.table(paste0(res.path,
#                                       '/busco/',
#                                       assembly.nam,
#                                       '-plasmodium_odb10-busco.batch_summary.txt'),
#                                header = TRUE) %>% 
#            mutate(assembly = assembly.nam)
#        }) %>% bind_rows %>% arrange(Complete)
# 
# assembly_stats.df <- full_join(assembly_numTranscript, assembly_busco, by = 'assembly') %>% arrange(desc(num_pir))
# 
# write_csv(arrange(assembly_stats.df, expt), 
#           path = 'assembly_stats.csv')

assembly_stats.df <- read_csv('assembly_stats_lifecycle.csv')

# Manually altered the assembly_stats csv file to include life cycle stages and experimental identifiers.

lapply(c('mosquito','asexual'), function(stages){
  ggplot(data = filter(assembly_stats.df, str_detect(lifecycle_stage, 
                                                     pattern = stages)) , 
         aes(x = Complete, 
             y = num_pir, 
             col = experiment_id,
             shape = lifecycle_stage)) +
    geom_point(size = 4) +
    scale_shape_manual(values = seq(1,10)) +
    xlab('Percentage of complete BUSCOs') +
    ylab('Number of pirs') +
    theme_classic() +
    guides(color = guide_legend(ncol = 2),
           size = guide_legend(ncol = 2),
           shape = guide_legend(ncol = 2)) +
    theme(legend.text = element_text(size = 7),
          legend.key.size = unit(.5,"cm"))
})

assembly_stats.df[assembly_stats.df$Complete > 50,] %>% arrange(num_pir)
assemblies_overFiftyBUSCO <- assembly_stats.df$assembly[assembly_stats.df$Complete > 50]
assembly_stats.df[assembly_stats.df$Complete <= 50,] %>% arrange(num_pir)

```

Doens't plateau, as expected this is probably an underestimate of the total pir transcriptome.

Annoyingly 50% Complete BUSCO excludes Meul22_PNG056 (373 pirs) and all other PNG pir samples.

Define subfam for each cluster based on the most frequent sub-family in each cluster, but only if there's at least five members in the cluster.

```{r assign_subfam_to_clusters}
assigned_subfam.df <- gephi_mcl.df %>% 
  select(-c(starts_with('I')), I1.4) %>% 
  group_by(I1.4) %>% 
  mutate(new_subfam = ifelse(sum(str_detect(subfam, pattern = '^(B|C|D|E|F|G|H|I|J|K)$')) > 5,
                             names(which.max(table(factor(str_subset(subfam, pattern = '^(B|C|D|E|F|G|H|I|J|K)$'))))),
                             'new')) %>% 
  #Combine with the assembly_stats
  left_join(assembly_stats.df)
#which.max code finds the most frequent members, table does the enumerating.

#Get unique names for each sub-family.
assigned_subfam_uniqName.df <- group_by(assigned_subfam.df, I1.4) %>% 
  slice_max(label) %>% 
  select(I1.4,new_subfam)
assigned_subfam_uniqName.df$new_subfam_uniq <- uniquify(assigned_subfam_uniqName.df$new_subfam, 
                                                        first_one = TRUE)

assigned_subfam.df <- inner_join(assigned_subfam.df, 
                                 assigned_subfam_uniqName.df,
                                 by = c('I1.4', 'new_subfam')) %>% 
  mutate(expt = str_extract(assembly, pattern = '^.+(?=_.+_vvx)'),
         assembly_id = paste0(experiment_id,'_',
                              str_extract(assembly, 
                                          pattern = '(?<=_).+(?=_)')))

```

TODO: Split vivax into the three ref genomes.

```{r subfam_dis_spec}

assigned_subfam_num.df <- assigned_subfam.df %>% 
  mutate(species = ifelse(species == 'vvx' & !str_detect(subfam, pattern = '^(B|C|D|E|F|G|H|I|J|K)$') ,
                          subfam,
                          ifelse(species == 'vvx' & str_detect(subfam, pattern = '^(B|C|D|E|F|G|H|I|J|K)$'),
                                 'vvxSal1',
                                 species))) %>% 
  group_by(species, I1.4, new_subfam_uniq) %>% 
  summarise(num_genes = n_distinct(label))

ggplot(assigned_subfam_num.df, aes(x = species, y = num_genes, fill = new_subfam_uniq)) +
         geom_col(position = 'fill')

assigned_subfam_prop.df <- group_by(assigned_subfam_num.df, 
                                    species) %>% 
  arrange(I1.4) %>% 
  mutate(prop_genes = num_genes/sum(num_genes))

# To order the sub-families from largest to smallest in the heatmap.
assigned_subfam_prop.df$new_subfam_uniq = factor(assigned_subfam_prop.df$new_subfam_uniq, 
                                                 levels = unique(assigned_subfam_prop.df$new_subfam_uniq))

assigned_subfam_prop.mat <- reshape2::dcast(assigned_subfam_prop.df, 
                                            new_subfam_uniq ~ species, 
                                            value.var = 'prop_genes')
rownames(assigned_subfam_prop.mat) <- assigned_subfam_prop.mat$new_subfam_uniq
assigned_subfam_prop.mat$new_subfam_uniq <- NULL

library('ComplexHeatmap')

assigned_subfam_prop.mat[is.na(assigned_subfam_prop.mat)] <- 0
# max_col <- max(na.omit(assigned_subfam_prop.mat))
Heatmap(t(assigned_subfam_prop.mat[1:26,]), 
        na_col = 'white',
        # cluster_rows = FALSE,
        # cluster_columns = FALSE,
        row_split = 4,
        # column_split = 3,
        row_names_gp = gpar(fontsize = 6),
        col = circlize::colorRamp2(c(0,0.0001,
                                     max(assigned_subfam_prop.mat)/4,
                                     max(assigned_subfam_prop.mat)),
                                   c('white',viridis::viridis(3))))

biplot(princomp(assigned_subfam_prop.mat))

```

```{r subfam_dis_expt}
assigned_subfam_num.df <- assigned_subfam.df %>% 
  filter(assembly %in% c(assemblies_overFiftyBUSCO, 'Meul22_PNG056_vvx')) %>% 
  group_by(expt, assembly_id, I1.4, new_subfam_uniq, Complete) %>% 
  summarise(num_genes = n_distinct(label))

ggplot(assigned_subfam_num.df, aes(x = assembly_id, y = num_genes, fill = new_subfam_uniq)) +
         geom_col(position = 'fill')

assigned_subfam_prop.df <- group_by(assigned_subfam_num.df, 
                                    assembly_id) %>% 
  arrange(I1.4) %>% 
  mutate(prop_genes = num_genes/sum(num_genes))

# To order the sub-families from largest to smallest in the heatmap.
assigned_subfam_prop.df$new_subfam_uniq = factor(assigned_subfam_prop.df$new_subfam_uniq, 
                                                 levels = unique(assigned_subfam_prop.df$new_subfam_uniq))

assigned_subfam_prop.mat <- reshape2::dcast(assigned_subfam_prop.df, 
                                            new_subfam_uniq ~ assembly_id, 
                                            value.var = 'prop_genes')
rownames(assigned_subfam_prop.mat) <- assigned_subfam_prop.mat$new_subfam_uniq
assigned_subfam_prop.mat$new_subfam_uniq <- NULL

assigned_subfam_prop.mat[is.na(assigned_subfam_prop.mat)] <- 0
# max_col <- max(na.omit(assigned_subfam_prop.mat))
subfam_ht <- Heatmap(t(assigned_subfam_prop.mat), 
        na_col = 'white',
        # cluster_rows = FALSE,
        # cluster_columns = FALSE,
        row_names_gp = gpar(fontsize = 6),
        column_names_gp = gpar(fontsize = 6),
        row_split = 6,
        column_split = 4,
        col = circlize::colorRamp2(c(0,0.0001,
                                     max(assigned_subfam_prop.mat)/4,
                                     max(assigned_subfam_prop.mat)),
                                   c('white',viridis::viridis(3))))

# How does this correspond with the BUSCO scores?

busco.mat <- assigned_subfam_prop.df %>% 
  select(assembly_id, Complete) %>% 
  mutate(Complete = as.numeric(Complete)) %>% 
  t 
names_busco.mat <- busco.mat[1,]
busco.mat <- t(matrix(as.numeric(busco.mat[-1,])))
duplicated_val <- !duplicated(names_busco.mat)
busco.mat <- busco.mat[duplicated_val]
names(busco.mat) <- names_busco.mat[duplicated_val]

busco_ht <- Heatmap(busco.mat,
                    name = 'busco',
        cluster_rows = FALSE,
        cluster_columns = FALSE,
        row_names_gp = gpar(fontsize = 6),
        column_names_gp = gpar(fontsize = 6),
                    col = circlize::colorRamp2(c(min(busco.mat),
                                     (max(busco.mat) + min(busco.mat))/2,
                                     max(busco.mat)),
                                   c(viridis::magma(3))))

draw(subfam_ht + busco_ht)

biplot(princomp(t(assigned_subfam_prop.mat)))

```
